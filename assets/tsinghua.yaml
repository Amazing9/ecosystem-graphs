---

# models


- type: model
  name: GLM-130B
  # General
  organization: Tsinghua (THUDM)
  description: GLM-130B is a 130B parameter bidirectional large language model trained on half English and half Chinese data.
  created_date:
    value: 2022-08-04
    explanation: The date the model website was made public
  url: https://keg.cs.tsinghua.edu.cn/glm-130b/
  model_card: None found
  modality: "Text (Chinese | English)"
  size: 130B parameters (dense model)
  analysis: ''
  # Construction
  dependencies: >
    - Pile
    - GLM-130B Chinese corpora
    - TO++ finetuning dataset
    - DeepStruct finetuning dataset
  training_emissions: ''
  training_time: ''
  training_hardware: THUDM 96 DGX-A100 (40G) cluster
  quality_control: ''
  # Downstream
  access: Full public access
  license:
    value: GLM-130B License
    explanation: >
      Unique model license. See https://github.com/THUDM/GLM-130B/blob/main/MODEL_LICENSE
  intended_uses: ''
  prohibited_uses: ''
  monitoring: ''
  feedback: ''
