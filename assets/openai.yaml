---

# Datasets

- type: dataset
  name: GPT-3 dataset
  # General
  organization: OpenAI
  description: >
    The GPT-3 dataset is the text corpus that was used to train the GPT-3
    model. Information on the GPT-3 dataset is limited to discussion in the
    paper introducing GPT-3
    [[Section 2.2]](https://arxiv.org/pdf/2005.14165.pdf#subsection.2.2).
  created_date: >
    2020-06-11; The date for the public announcement of GPT-3. The GPT-3
    dataset didn't have a specific release date separate from the model
    [[Open AI Blog Post]](https://openai.com/blog/openai-api/).
  url: https://arxiv.org/pdf/2005.14165.pdf
  datasheet: None; No datasheet available as of 2022-04-04.
  modality: Text (English)
  size: 570 GB
  sample: []
  analysis: >
    The GPT-3 paper, which also introduces the GPT-3 dataset, provides a limited
    analysis on the GPT-3 dataset, reporting the dirtiness of the dataset after
    the it was filtered for text occurring in common benchmarking tasks.
    The authors report that "as the dataset becomes more contaminated, the
    variance of the clean/all fraction increases, but there is no apparent bias
    towards improved or degraded performance"
    [[Appendix C]](https://arxiv.org/pdf/2005.14165.pdf#appendix.C).
  # Construction
  dependencies: []
  license: >
    Unknown; There is no known license specific to the GPT-3 dataset, however,
    the governing organization, OpenAI, licensed GPT-3 to Microsoft, which
    makes it likely that the GPT-3 dataset was also licensed
    [[OpenAI Blog Post]]
    (https://openai.com/blog/openai-licenses-gpt-3-technology-to-microsoft/).
  included: >
    The dataset is composed several NLP corpora: Common Crawl (filtered, 60%),
    WebText2 (22%), Books1 (8%), Books2 (8%), Wikipedia (3%)
    [[Section 2.2]](https://arxiv.org/pdf/2005.14165.pdf#subsection.2.2).
  excluded: >
    The Common Crawl dataset was processed using a classifier that kept high
    quality documents and filtered low quality documents. WebText was used as a
    proxy for high quality documents
    [[Appendix A]](https://arxiv.org/pdf/2005.14165.pdf#appendix.A).
  quality_control: >
    In addition to excluding low quality documents from the Common Crawl
    dataset, the authors fuzzily deduplicated documents within each dataset, by
    removing documents that have high overlap with each other. The same
    procedure was followed to fuzzily deduplicate WebText from Common Crawl
    [[Appendix A]](https://arxiv.org/pdf/2005.14165.pdf#appendix.A).
    Text occuring in benchmark datasets were also partially removed
    [[Appendix C]](https://arxiv.org/pdf/2005.14165.pdf#appendix.C).
  # Downstream
  access: >
    The GPT-3 dataset isn't released to the public, but it may be available
    to Microsoft through the GPT-3 licencing agreement between OpenAI and
    Microsoft [[OpenAI Blog Post]]
    (https://openai.com/blog/openai-licenses-gpt-3-technology-to-microsoft/).
  intended_uses: >
    The intended use of the GPT-3 dataset is to train large language models.
  prohibited_uses: >
    Unknown; OpenAI didn't provide a list of prohibited uses specifically for
    the GPT-3 dataset. However, public OpenAI products are governed by the
    OpenAI Terms of Use, which may also apply to the OpenAI dataset.
    The OpenAI Terms of Use prohibit the following:
    (i) Illegal activities, such as child pornography, gambling, cybercrime,
    piracy, violating copyright, trademark or other intellectual property laws;
    (ii) Accessing or authorizing anyone to access the APIs from an embargoed
    country, region, or territory as prohibited by the U.S. government;
    (iii) Threatening, stalking, defaming, defrauding, degrading, victimizing
    or intimidating anyone for any reason
    [[Open AI Terms of Use]](https://openai.com/api/policies/terms/).
  monitoring: >
    Unknown; There are no known (internal or external) monitoring mechanisms
    that are in place for the use of the GPT-3 dataset as of 2022-04-04.
  feedback: >
    Unknown; There are no known (internal or external) feedback mechanisms for
    the GPT-3 dataset as of 2022-04-04.

- type: dataset
  name: Codex dataset
  # General
  organization: OpenAI
  description: none
  created_date: none
  url: https://arxiv.org/pdf/2107.03374.pdf
  datasheet: none
  modality: Text (English)
  size: 159GB
  sample: []
  analysis: See the paper (Section 3.1).
  # Construction
  dependencies: []
  license: none
  included: GitHub
  excluded: autogenerated files; files with average line length > 100, maximum line length > 1000, or few alphanumeric characters
  quality_control: unknown
  # Downstream
  access: none
  intended_uses: Training language models.
  prohibited_uses: none
  monitoring: none
  feedback: none

# Models

- type: model
  name: GPT-3
  # General
  organization: OpenAI
  description: >
    GPT-3 is an autoregressive large language model.
  created_date: >
    2020-06-11; The date that GPT-3 was announced to the public
    [[Open AI Blog Post]](https://openai.com/blog/openai-api/).
  url: https://arxiv.org/pdf/2005.14165.pdf
  model_card: https://github.com/openai/gpt-3/blob/master/model-card.md
  modality: Text (English)
  size: >
    175B parameters; GPT-3 comes in several sizes. Here we report the largest
    GPT-3 model size. All the model sizes of GPT-3 can be seen in the paper
    [[Table 2.1]](https://arxiv.org/pdf/2005.14165.pdf#table.caption.7).
  analysis: >
    The GPT-3 model was evaluated on language modeling, closed-book question
    answering, translation, Winograd-style tasks, commonsense reasoning,
    reading comprehension, SuperGLUE, NLI, synthetic tasks, and generation
    [[Section 4]](https://arxiv.org/pdf/2005.14165.pdf#section.4);
    as well as on fairness and biases
    [[Section 6]](https://arxiv.org/pdf/2005.14165.pdf#section.6).
  # Construction
  dependencies:
  - GPT-3 dataset
  training_emissions: >
    552.1 tCO2e; Estimate of the CO2(e) emissions for GPT-3 were not provided
    by OpenAI, but they were provided by a follow up work investigating the CO2
    equivalent emissions (CO2e) of GPT-3
    [[Patterson et al.]]
    (https://arxiv.org/ftp/arxiv/papers/2104/2104.10350.pdf).
  training_time: >
    3.64E+03 PF-days; The time required to train the GPT-3 model with 175B
    parameters.
  training_hardware: >
    Azure; The original paper doesn't specify the training hardware for GPT-3,
    but a follow up blog post indicates that it was trained on a cluster on
    Azure cluster, using 10000 GPUs with 400 Gbps
    [[Microsoft Blog Post]]
    (https://blogs.microsoft.com/ai/openai-azure-supercomputer/).
  quality_control: >
    One quality control method OpenAI employed was releasing GPT-3 only through
    the OpenAI API. OpenAI states that it is easier to respond to misuse when
    the access to the model is gated through the API. It also hints that it
    plans to broaden the API access over time based on the amount of misuse
    [[OpenAI API Blog Post]](https://openai.com/blog/openai-api/).
    The authors identify potential misuses of GPT-3 in the paper and analyze
    it for fairness, bias and representation issues, but do not identify
    mitigation strategies
    [[Section 6]](https://arxiv.org/pdf/2005.14165.pdf#section.6).
    This section was last updated on 2022-04-04.
  # Downstream
  access: >
    The GPT-3 model isn't fully released to the public, but
    it was made available to Microsoft through the licencing agreement between
    OpenAI and Microsoft
    [[OpenAI Blog Post]]
    (https://openai.com/blog/openai-licenses-gpt-3-technology-to-microsoft/).
    The public can access the model through the Open AI API, which is available
    in supported countries
    [[Supported Countries]](https://beta.openai.com/docs/supported-countries)
    [[OpenAI API]](https://openai.com/api/).
    This field was last updated on 04-04-2022.
  license: >
    GPT-3 is exclusively licensed to OpenAI and Microsoft
    [[OpenAI Blog Post]]
    (https://openai.com/blog/openai-licenses-gpt-3-technology-to-microsoft/).
    This field was last updated on 04-04-2022.
  intended_uses: >
    GPT-3 was intended to be use through the OpenAI API by developers for
    language applications. Other intended use of GPT-3 include researchers
    accessing the model through the API to study its paradigms
    [[Model Card]](https://github.com/openai/gpt-3/blob/master/model-card.md).
  prohibited_uses: >
    Access to GPT-3 is governed by Open AI API Usage Guidelines and API Terms
    of Use, prohibiting the use of the API in a way that causes societal harm.
    [[Usage Guidelines]]
    (https://beta.openai.com/docs/usage-guidelines/content-policy)
    [[Terms of Use]](https://openai.com/api/policies/terms/).
    The list of disallowed applications can be found in the usage guidelines
    [[Disallowed Applications]]
    (https://beta.openai.com/docs/usage-guidelines/disallowed-applications).
  monitoring: >
    OpenAI reviews all use cases of the model
    [[Model Card]](https://github.com/openai/gpt-3/blob/master/model-card.md).
  feedback: >
    Feedback for GPT-3 can be provided on the feedback form linked in the
    model card
    [[Model Card]](https://github.com/openai/gpt-3/blob/master/model-card.md).
    The form is especially meant to collect feedback on concerns about misuse,
    synthetic text detection, bias, and risk of generative language models.

- type: model
  name: Codex
  # General
  organization: OpenAI
  created_date: "2021-08-10"
  url: https://arxiv.org/pdf/2107.03374.pdf
  model_card: none
  modality: text (English and code)
  size: 12B parameters, supervised fine-tuning
  analysis: Evaluated on HumanEval using pass@k and BLEU scores; see the paper (Section 2).
  # Construction
  dependencies:
  - GPT-3
  - Codex dataset
  training_emissions: unknown
  training_time: Authors estimate hundreds of petaflop/s-days of compute; see the paper (Section 7.6).
  training_hardware: Azure
  quality_control: The model is not released; see the paper for legal implications (Section 7.7) and risk mitigation (Section 7.8).
  # Downstream
  access: Available via the [OpenAI API](https://openai.com/api/); full model access to Microsoft for [GitHub Copilot](https://copilot.github.com/).
  license: Exclusive license to Microsoft.
  intended_uses: Coding assistant.
  prohibited_uses: unknown
  monitoring: none
  feedback: none

- type: model
  name: InstructGPT
  # General
  organization: OpenAI
  created_date: "2022-01-27"
  url: https://openai.com/blog/instruction-following/
  model_card: https://github.com/openai/following-instructions-human-feedback/blob/main/model-card.md
  modality: text (English and code)
  size: 175B parameters, fine-tuned with supervised fine-tuning, reward modeling, reinforcement learning
  analysis: https://arxiv.org/abs/2203.02155
  # Construction
  dependencies:
  - GPT-3
  training_emissions: unknown
  training_time: 175B SFT model required 4.9 petaflops/s-days; 175B PPO-ptx model required 60 petaflops/s-days
  training_hardware: unknown
  quality_control: The model is not released.
  # Downstream
  access: Available via the [OpenAI API](https://openai.com/api/)
  license: Exclusive license to Microsoft
  intended_uses: Performing tasks through instructions in plain language.
  prohibited_uses: OpenAI prohibits the use of the model to generate restricted content per their [content policy](https://beta.openai.com/docs/usage-guidelines/content-policy). Other disallowed applications are listed in the [disallowed applications](https://beta.openai.com/docs/usage-guidelines/disallowed-applications) list.
  monitoring: OpenAI reviews all use cases of the model.
  feedback: none

- type: application
  name: OpenAPI API
  # General
  organization: OpenAI
  description: >
    OpenAI API is a general purpose "text in, text out" interface connecting
    users with a suite of large language models. The API was initially released
    as a gateway to GPT-3, but it now supports access to other, more
    specialized OpenAI models. This field was last updated on 2022-04-05
    [[Open AI Blog Post]](https://openai.com/blog/openai-api/).
  created_date: >
    2020-06-11; The date that OpenAI API was announced to the public
    [[Open AI Blog Post]](https://openai.com/blog/openai-api/).
  url: https://openai.com/api/
  # Construction
  dependencies:
  - GPT-3
  - Codex
  - InstructGPT
  adaptation: >
    Although initially started with GPT-3, soon after the API was made public,
    OpenAI deployed the InstructGPT models, and made them the default models on
    the API
    [[OpenAI Blog Post]](https://openai.com/blog/instruction-following/).
    Unlike their predecessors, these models are trained with humans in the loop,
    are more truthful and less toxic.
  output_space: >
    Given a prompting text, the OpenAI API provides access to text completions,
    and log probabilities. The support for text and code embeddings were added
    on 2022-01-25
    [[OpenAI Blog Post]]
    (https://openai.com/blog/introducing-text-and-code-embeddings/).
  quality_control: >
    Given a prompt, OpenAI API checks whether a completion contains unsafe
    language using its filters and marks the completion accordingly if so.
    The API also provides developers with special endpoints that scope the
    API usage. OpenAI also developed user guidelines to help developers
    understand safety issues
    [[OpenAI API]](https://openai.com/api/).
    This field was last updated on 2022-04-04.
  # Downstream
  access: >
    The OpenAI API is available to the public in supported countries
    [[Supported Countries]](https://beta.openai.com/docs/supported-countries)
    [[OpenAI API]](https://openai.com/api/).
    This field was last updated on 2022-04-04.
  terms_of_service: https://openai.com/api/policies/terms/
  license: >
    Per the Terms of Use, a limited license is provided to the users during
    their use of the API
    [[Section 2]](https://openai.com/api/policies/terms/).
  intended_uses: >
    OpenAI API was designed to be used by developers to empower applications,
    and researchers to study language models
    [[Section 3]](https://openai.com/api/policies/terms/).
  prohibited_uses: >
    OpenAI API Terms of Use prohibits the use of the API in a way violating
    the applicable law, including: (i) "Illegal activities, such as child
    pornography, gambling, cybercrime, piracy, violating copyright,
    trademark or other intellectual property laws"; (ii) "Accessing or
    authorizing anyone to access the APIs from an embargoed country, region, or
    territory as prohibited by the U.S. government"; (iii) "Threatening,
    stalking, defaming, defrauding, degrading, victimizing or intimidating
    anyone for any reason".
    The usage requirements are detailed in the Terms of Use
    [[Section 3]](https://openai.com/api/policies/terms/).
  monitoring: >
    OpenAI may monitor the API use to ensure "quality and improve OpenAI
    systems, products and services; perform research; and ensure compliance"
    with the Terms of Service and all applicable laws. Users of the API will
    give OpenAI reasonable access to their application to monitor compliance
    with the terms listed in the Terms of Service
    [[Section 5(b)]](https://openai.com/api/policies/terms/).
    Apps using the OpenAI API should submit an application once they are
    deployed to real users. The review form takes 10 minutes to complete and
    over 97% of the applications are directly accepted or conditionally
    accepted. The applicants are notified of the decision within 2 business
    days
    [[App Review Guidelines]]
    (https://beta.openai.com/docs/usage-guidelines/app-review).
    This field was last updated on 2022-04-05.
  feedback: >
    Unknown; There is no known specific feedback channel for the OpenAI API,
    but OpenAI support theme can be reached via email at support at openai.com.
    This field was last updated on 2022-04-05.
  # Deployment
  monthly_active_users: >
    Unknown; The number of monthly active users is not known publicly, but
    OpenAI mentioned that the API was being used by tens of thousands of
    developers in a blog post from 2021-11-18
    [[OpenAI Blog Post]](https://openai.com/blog/api-no-waitlist/).
    This field was last updated on 2022-04-05.
  user_distribution: >
    Unknown; The distribution of the users is not known, but we estimate
    majority of the users to be developers based in the United States.
    This field was last updated on 2022-04-05.
  failures: >
    Unknown; There are no known documented failures of the OpenAI API at the
    time of writing. This field was last updated on 2022-04-05.

- type: application
  name: Duolingo
  # General
  organization: Duolingo
  created_date: "2020-06-11"
  url: https://openai.com/api/
  # Construction
  dependencies:
  - OpenAPI API
  adaptation: unknown
  output_space: French grammar corrections
  quality_control: unknown
  # Downstream
  access: none
  license: none
  terms_of_service: https://www.duolingo.com/terms
  intended_uses: none
  prohibited_uses: none
  monitoring: unknown
  feedback: none
  # Deployment
  monthly_active_users: 42 million (all languages)
  user_distribution: unknown
  failures: unknown

- type: application
  name: Viable
  # General
  organization: Viable
  created_date: unknown
  url: https://www.askviable.com/
  # Construction
  dependencies:
  - OpenAPI API
  adaptation: none
  output_space: question and answer, summarization, sentiment analysis,topic identification
  quality_control: unknown
  # Downstream
  access: none
  license: none
  terms_of_service: https://www.askviable.com/terms-of-service
  intended_uses: none
  prohibited_uses: none
  monitoring: unknown
  feedback: unknown
  # Deployment
  monthly_active_users: unknown
  user_distribution: unknown
  failures: unknown

- type: application
  name: HyperWrite
  # General
  organization: OthersideAI
  created_date: unknown
  url: https://hyperwriteai.com/
  # Construction
  dependencies:
  - OpenAPI API
  adaptation: none
  output_space: generation
  quality_control: unknown
  # Downstream
  access: none
  license: none
  terms_of_service: https://hyperwriteai.com/terms
  intended_uses: none
  prohibited_uses: none
  monitoring: unknown
  feedback: unknown
  # Deployment
  monthly_active_users: unknown
  user_distribution: unknown
  failures: unknown
