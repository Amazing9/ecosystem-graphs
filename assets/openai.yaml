---

# Datasets

- type: dataset
  name: GPT-3 dataset
  # General
  organization: OpenAI
  created_date: none
  url: https://arxiv.org/pdf/2005.14165.pdf
  datasheet: none
  modality: text (English)
  size: 570GB
  sample: []
  analysis: See the paper (Section 2.2).
  # Construction
  dependencies: []
  license: none
  included: WebText2, Books1, Books2, Wikipedia, Common Crawl (filtered)
  excluded: parts of Common Crawl that look less like Wikipedia, WebText, or books corpus; some duplicates
  quality_control: fuzzy deduplication, removing WebText from CommonCrawl, filtered Common Crawl for similarity to Wikipedia, WebText, or books corpus
  # Downstream
  access: Not released to the public, full dataset access to OpenAI
  intended_uses: Training language models.
  prohibited_uses: none
  monitoring: none
  feedback: none

- type: dataset
  name: Codex dataset
  # General
  organization: OpenAI
  created_date: none
  url: https://arxiv.org/pdf/2107.03374.pdf
  datasheet: none
  modality: text (English)
  size: 159GB
  sample: []
  analysis: See the paper (Section 3.1).
  # Construction
  dependencies: []
  license: none
  included: GitHub
  excluded: autogenerated files; files with average line length > 100, maximum line length > 1000, or few alphanumeric characters
  quality_control: unknown
  # Downstream
  access: none
  intended_uses: Training language models.
  prohibited_uses: none
  monitoring: none
  feedback: none

# Models

- type: model
  name: GPT-3
  # General
  organization: OpenAI
  created_date: "2020-06-11"
  url: https://arxiv.org/pdf/2005.14165.pdf
  model_card: https://github.com/openai/gpt-3/blob/master/model-card.md
  modality: text (English)
  size: Autoregressive Transformer with 175B parameters
  analysis: Evaluated on language modeling, closed-book question answering, translation, Winograd-style tasks, commonsense reasoning, reading comprehension, SuperGLUE, NLI, synthetic tasks, generation
  # Construction
  dependencies:
  - GPT-3 dataset
  training_emissions: 552.1 tCO2e (estimate from https://arxiv.org/abs/2104.10350)
  training_time: 3.64E+03 PF-days
  training_hardware: Trained on [Azure supercomputer](https://blogs.microsoft.com/ai/openai-azure-supercomputer/), which has 10000 GPUs with 400 Gbps
  quality_control: The model is not released.
  # Downstream
  access: Open to anyone in [supported countries](https://beta.openai.com/docs/supported-countries) via [API access](https://openai.com/api/); full model access to Microsoft
  license: exclusive license to Microsoft
  intended_uses: unknown
  prohibited_uses: OpenAI prohibits the use of the model to generate restricted content per their [content policy](https://beta.openai.com/docs/usage-guidelines/content-policy). Other disallowed applications are listed in the [disallowed applications](https://beta.openai.com/docs/usage-guidelines/disallowed-applications) list.
  monitoring: OpenAI reviews all use cases of the model.
  feedback: Feedback form is [here](https://docs.google.com/forms/d/e/1FAIpQLSf1-7D2eiOcxz9KJSQ0Ie_R6ST_TsNXOvJE9MUyGax1NYkMfQ/viewform)

- type: model
  name: Codex
  # General
  organization: OpenAI
  created_date: "2021-08-10"
  url: https://arxiv.org/pdf/2107.03374.pdf
  model_card: none
  modality: text (English and code)
  size: 12B parameters, supervised fine-tuning
  analysis: Evaluated on HumanEval using pass@k and BLEU scores; see the paper (Section 2).
  # Construction
  dependencies:
  - GPT-3
  - Codex dataset
  training_emissions: unknown
  training_time: Authors estimate hundreds of petaflop/s-days of compute; see the paper (Section 7.6).
  training_hardware: Azure
  quality_control: The model is not released; see the paper for legal implications (Section 7.7) and risk mitigation (Section 7.8).
  # Downstream
  access: Available via the [OpenAI API](https://openai.com/api/); full model access to Microsoft for [GitHub Copilot](https://copilot.github.com/).
  license: Exclusive license to Microsoft.
  intended_uses: Coding assistant.
  prohibited_uses: unknown
  monitoring: none
  feedback: none

- type: model
  name: InstructGPT
  # General
  organization: OpenAI
  created_date: "2022-01-27"
  url: https://openai.com/blog/instruction-following/
  model_card: https://github.com/openai/following-instructions-human-feedback/blob/main/model-card.md
  modality: text (English and code)
  size: 175B parameters, fine-tuned with supervised fine-tuning, reward modeling, reinforcement learning
  analysis: https://arxiv.org/abs/2203.02155
  # Construction
  dependencies:
  - GPT-3
  training_emissions: unknown
  training_time: 175B SFT model required 4.9 petaflops/s-days; 175B PPO-ptx model required 60 petaflops/s-days
  training_hardware: unknown
  quality_control: The model is not released.
  # Downstream
  access: Available via the [OpenAI API](https://openai.com/api/)
  license: Exclusive license to Microsoft
  intended_uses: Performing tasks through instructions in plain language.
  prohibited_uses: OpenAI prohibits the use of the model to generate restricted content per their [content policy](https://beta.openai.com/docs/usage-guidelines/content-policy). Other disallowed applications are listed in the [disallowed applications](https://beta.openai.com/docs/usage-guidelines/disallowed-applications) list.
  monitoring: OpenAI reviews all use cases of the model.
  feedback: none

- type: application
  name: OpenAPI API
  # General
  organization: OpenAI
  created_date: "2020-06-11"
  url: https://openai.com/api/
  # Construction
  dependencies:
  - GPT-3
  - Codex
  - InstructGPT
  adaptation: none?
  output_space: text completions, log probabilities, and embeddings
  quality_control: TODO
  # Downstream
  access: Available to everyone excluding those in [embargoed countries](https://beta.openai.com/docs/supported-countries)
  license: Section 2a of [Terms of Use](https://openai.com/api/policies/terms/)
  terms_of_service: https://openai.com/api/policies/terms/
  intended_uses: TODO
  prohibited_uses: illegal activities (child pornography, gambling, cybercrime, piracy, violating copyright, trademark or other intellectual property laws) and threatening, stalking, defaming, defrauding, degrading, victimizing or intimidating anyone [terms of service](https://openai.com/api/policies/terms/) API cannot be used to generate these kinds of content hate speech, harassment, violence, self-harm, adult, political, spam, deception, malware [Usage Guidelines](https://beta.openai.com/docs/usage-guidelines)
  monitoring: Use of API is monitored, per Section 5b of [Terms of Use](https://openai.com/api/policies/terms/)
  feedback: private feedback at support @ openai.com
  # Deployment
  monthly_active_users: unknown
  user_distribution: unknown
  failures: unknown

- type: application
  name: Duolingo
  # General
  organization: Duolingo
  created_date: "2020-06-11"
  url: https://openai.com/api/
  # Construction
  dependencies:
  - GPT-3
  adaptation: unknown
  output_space: French grammar corrections
  quality_control: unknown
  # Downstream
  access: none
  license: none
  terms_of_service: https://www.duolingo.com/terms
  intended_uses: none
  prohibited_uses: none
  monitoring: unknown
  feedback: none
  # Deployment
  monthly_active_users: 42 million (all languages)
  user_distribution: unknown
  failures: unknown

- type: application
  name: Viable
  # General
  organization: Viable
  created_date: unknown
  url: https://www.askviable.com/
  # Construction
  dependencies:
  - GPT-3
  adaptation: none
  output_space: question and answer, summarization, sentiment analysis,topic identification
  quality_control: unknown
  # Downstream
  access: none
  license: none
  terms_of_service: https://www.askviable.com/terms-of-service
  intended_uses: none
  prohibited_uses: none
  monitoring: unknown
  feedback: unknown
  # Deployment
  monthly_active_users: unknown
  user_distribution: unknown
  failures: unknown

- type: application
  name: HyperWrite
  # General
  organization: OthersideAI
  created_date: unknown
  url: https://hyperwriteai.com/
  # Construction
  dependencies:
  - GPT-3
  adaptation: none
  output_space: generation
  quality_control: unknown
  # Downstream
  access: none
  license: none
  terms_of_service: https://hyperwriteai.com/terms
  intended_uses: none
  prohibited_uses: none
  monitoring: unknown
  feedback: unknown
  # Deployment
  monthly_active_users: unknown
  user_distribution: unknown
  failures: unknown
